{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Clinical Encounter Demo\n",
    "\n",
    "## Overview\n",
    "This demo uses a Retrieval Augmented Generation (RAG) technique to use previously diagnosed conditions from a sample patient's health record to aid a clinician during a clinical encounter. The concept is not meant to be used in the real world, but aims to highlight the art-of-the-possible with generative AI tools such as Amazon Bedrock in a healthcare environment. It also discusses some of the prompt engineering techniques to achieve consistent, high-quality responses from large language models such as Anthropic's Claude (v2).\n",
    "\n",
    "### Prerequisites\n",
    "* It can run either in a local environment or in SageMaker Studio with the **`Data Science 3.0`** kernel on an **`ml.t3.medium`** instance.\n",
    "* The demo was build and tested using boto3 version 1.33.6. Verify that the environment is running a version of boto3 at least 1.33 or higher.\n",
    "* Verify that model access to Anthropic's Claude v2 is granted to the account being used, see documentation here: [Amazon Bedrock Model Access](https://docs.aws.amazon.com/bedrock/latest/userguide/model-access.html)\n",
    "* The user or permission context running the notebook needs to have InvokeModel permissions for the **anthropic.claude-v2** Bedrock model\n",
    "\n",
    "Sample IAM Policy:\n",
    "```\n",
    "{\n",
    "    \"Sid\": \"BedrockInvokeClaudeV2\",\n",
    "    \"Effect\": \"Allow\",\n",
    "    \"Action\": \"bedrock:InvokeModel\",\n",
    "    \"Resource\": \"arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Testing the Environment\n",
    "\n",
    "### 1.1. Check boto3 version\n",
    "Ensure the boto3 version is 1.33 or higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boto3              1.33.6\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Setting up the Bedrock client\n",
    "Create the Bedrock client and define the parameters that will not change for the rest of the demo. This demo uses Anthropic's Claude v2 model and sends/receives JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "bedrock_runtime = boto3.client(service_name='bedrock-runtime',region_name='us-east-1')\n",
    "\n",
    "model_id = 'anthropic.claude-v2'\n",
    "accept = 'application/json'\n",
    "content_type = 'application/json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Test the Bedrock client\n",
    "We can test permissions and setup by sending a prompt and reading the response. Let's attempt to summarize all 101,000 words of USA's Health Insurance Portability and Accountability Act (HIPAA) to 50 words for 5th graders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here is an explanation of HIPAA for a 5th grader in 47 words:\n",
      "\n",
      "HIPAA is a law that keeps your private health information safe. Doctors, nurses, and hospitals can't share things about your health with other people without your OK. This stops strangers from seeing your medical records and keeps your health details just between you and your doctor.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\\n\\nHuman: explain HIPAA to a 5th grader in less than 50 words\\n\\nAssistant:\"\n",
    "\n",
    "body = json.dumps({\n",
    "    \"prompt\": prompt,\n",
    "    \"max_tokens_to_sample\": 1000,\n",
    "    \"temperature\": 0.1,\n",
    "    \"top_p\": 0.9,\n",
    "})\n",
    "\n",
    "response = bedrock_runtime.invoke_model(body=body, modelId=model_id, accept=accept, contentType=content_type)\n",
    "response_body = json.loads(response.get('body').read())\n",
    "print(response_body.get('completion'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Working with FHIR-formatted Healthcare Records\n",
    "This demo uses sample data generated in Amazon HealthLake using an open-source library called Synthea. This demo will not directly interact with HealthLake, but the companion file `healthlake_sample_records.json` contains this sample data exactly as presented by HealthLake using a GET search. It is an array of FHIR-formatted Conditions for a single patient.\n",
    "\n",
    "FHIR is a set of rules and specifications intended to standardize exchanging health data. To ensure its flexibility, it contains significant amounts of metadata that may not be useful in many contexts. For our purpose, we want to minimize the amount of extraneous data we send to the large language model to ensure that it will only use the minimum data necessary for our prompt and optimize the efficiency of the request.\n",
    "\n",
    "### 2.1. FHIR record optimization\n",
    "The follow is a single Condition FHIR record. LLM models process data in units called tokens. While Claude v2 can accept up to 100,000 tokens, tokens are also used to price usage of the model. Streamlining the number of tokens sent by only sending the necessary data can contribute to higher quality output at an efficient rate.\n",
    "\n",
    "The following is a single JSON-formatted FHIR record for a patient Condition:\n",
    "```\n",
    "{\"resource\":{\"resourceType\":\"Condition\",\"id\":\"71c4183a-390e-496d-b410-81fe13ad8b1d\",\"meta\":{\"lastUpdated\":\"2023-09-25T21:19:39.299Z\"},\"clinicalStatus\":{\"coding\":[{\"system\":\"http://terminology.hl7.org/CodeSystem/condition-clinical\",\"code\":\"resolved\"}]},\"verificationStatus\":{\"coding\":[{\"system\":\"http://terminology.hl7.org/CodeSystem/condition-ver-status\",\"code\":\"confirmed\"}]},\"code\":{\"coding\":[{\"system\":\"http://snomed.info/sct\",\"code\":\"302932006\",\"display\":\"Tear of medial meniscus of knee\"}],\"text\":\"Tear of medial meniscus of knee\"},\"subject\":{\"reference\":\"Patient/24042b1f-5acb-449f-9948-462618aba6d6\"},\"encounter\":{\"reference\":\"Encounter/6deb0a82-03f9-45e0-a2e8-51dacb1662ee\"},\"onsetDateTime\":\"2022-02-01T10:19:48-08:00\",\"abatementDateTime\":\"2022-03-15T11:48:48-08:00\",\"recordedDate\":\"2022-03-15T10:19:48-08:00\"},\"search\":{\"mode\":\"match\"}}\n",
    "```\n",
    "This is roughly 280 tokens.\n",
    "\n",
    "If we reduce this record to only the fields strictly necessary for our request, we get the following JSON-formatted output:\n",
    "```\n",
    "{\"clinicalStatus\":\"resolved\",\"verificationStatus\":\"confirmed\",\"code\":\"302932006\",\"condition\":\"Tear of medial meniscus of knee\",\"onsetDateTime\":\"2022-02-01\",\"abatementDateTime\":\"2022-03-15\",\"recordedDate\":\"2022-03-15\"}\n",
    "```\n",
    "This is roughly 60 tokens. We've also reduced the complexity of the record by flattening the JSON to a single dimension and clearly labeled the condition \"Tear of medial meniscus of knee\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Optimization code\n",
    "The following code ingests the FHIR-formatted Condition records and reduces each Condition to this minimal set of fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"conditions\": [\n",
      "    {\n",
      "      \"clinicalStatus\": \"resolved\",\n",
      "      \"verificationStatus\": \"confirmed\",\n",
      "      \"code\": \"840544004\",\n",
      "      \"condition\": \"Suspected COVID-19\",\n",
      "      \"onsetDateTime\": \"2020-03-01\",\n",
      "      \"abatementDateTime\": \"2020-03-01\",\n",
      "      \"recordedDate\": \"2020-03-01\"\n",
      "    },\n",
      "    {\n",
      "      \"clinicalStatus\": \"active\",\n",
      "      \"verificationStatus\": \"confirmed\",\n",
      "      \"code\": \"233678006\",\n",
      "      \"condition\": \"Childhood asthma\",\n",
      "      \"onsetDateTime\": \"2005-10-15\",\n",
      "      \"recordedDate\": \"2005-10-15\"\n",
      "    },\n",
      "    {\n",
      "      \"clinicalStatus\": \"resolved\",\n",
      "      \"verificationStatus\": \"confirmed\",\n",
      "      \"code\": \"444814009\",\n",
      "      \"condition\": \"Viral sinusitis (disorder)\",\n",
      "      \"onsetDateTime\": \"2019-09-20\",\n",
      "      \"abatementDateTime\": \"2019-09-27\",\n",
      "      \"recordedDate\": \"2019-09-20\"\n",
      "    },\n",
      "    {\n",
      "      \"clinicalStatus\": \"active\",\n",
      "      \"verificationStatus\": \"confirmed\",\n",
      "      \"code\": \"232353008\",\n",
      "      \"condition\": \"Perennial allergic rhinitis with seasonal variation\",\n",
      "      \"onsetDateTime\": \"2006-10-29\",\n",
      "      \"recordedDate\": \"2006-10-29\"\n",
      "    },\n",
      "    {\n",
      "      \"clinicalStatus\": \"resolved\",\n",
      "      \"verificationStatus\": \"confirmed\",\n",
      "      \"code\": \"386661006\",\n",
      "      \"condition\": \"Fever (finding)\",\n",
      "      \"onsetDateTime\": \"2020-03-01\",\n",
      "      \"abatementDateTime\": \"2020-03-24\",\n",
      "      \"recordedDate\": \"2020-03-01\"\n",
      "    },\n",
      "    {\n",
      "      \"clinicalStatus\": \"resolved\",\n",
      "      \"verificationStatus\": \"confirmed\",\n",
      "      \"code\": \"302932006\",\n",
      "      \"condition\": \"Tear of medial meniscus of knee\",\n",
      "      \"onsetDateTime\": \"2022-02-01\",\n",
      "      \"abatementDateTime\": \"2022-03-15\",\n",
      "      \"recordedDate\": \"2022-03-15\"\n",
      "    },\n",
      "    {\n",
      "      \"clinicalStatus\": \"resolved\",\n",
      "      \"verificationStatus\": \"confirmed\",\n",
      "      \"code\": \"195662009\",\n",
      "      \"condition\": \"Acute viral pharyngitis (disorder)\",\n",
      "      \"onsetDateTime\": \"2017-09-26\",\n",
      "      \"abatementDateTime\": \"2017-10-08\",\n",
      "      \"recordedDate\": \"2017-09-26\"\n",
      "    },\n",
      "    {\n",
      "      \"clinicalStatus\": \"resolved\",\n",
      "      \"verificationStatus\": \"confirmed\",\n",
      "      \"code\": \"269113006\",\n",
      "      \"condition\": \"Acute meniscal tear, medial\",\n",
      "      \"onsetDateTime\": \"2022-08-01\",\n",
      "      \"abatementDateTime\": \"2022-09-15\",\n",
      "      \"recordedDate\": \"2022-09-15\"\n",
      "    },\n",
      "    {\n",
      "      \"clinicalStatus\": \"resolved\",\n",
      "      \"verificationStatus\": \"confirmed\",\n",
      "      \"code\": \"267102003\",\n",
      "      \"condition\": \"Sore throat symptom (finding)\",\n",
      "      \"onsetDateTime\": \"2020-03-01\",\n",
      "      \"abatementDateTime\": \"2020-03-24\",\n",
      "      \"recordedDate\": \"2020-03-01\"\n",
      "    },\n",
      "    {\n",
      "      \"clinicalStatus\": \"active\",\n",
      "      \"verificationStatus\": \"confirmed\",\n",
      "      \"code\": \"72892002\",\n",
      "      \"condition\": \"Normal pregnancy\",\n",
      "      \"onsetDateTime\": \"2020-01-09\",\n",
      "      \"recordedDate\": \"2020-01-09\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "with open('./healthlake_sample_records.json') as file:\n",
    "    healthlake_data = json.load(file)\n",
    "\n",
    "field_list = ['clinicalStatus','verificationStatus','code','onsetDateTime','abatementDateTime','recordedDate']\n",
    "entries = []\n",
    "for entry in healthlake_data[\"entry\"]:\n",
    "    entries.append(entry['resource'])\n",
    "\n",
    "conditions_obj = {}\n",
    "conditions_obj[\"conditions\"] = []\n",
    "\n",
    "for condition in entries:\n",
    "    condition_json_obj = {}\n",
    "    for field in field_list:\n",
    "        if not condition.get(field) == None:\n",
    "            val = datetime.fromisoformat(condition[field]).strftime('%Y-%m-%d') if 'Date' in field else condition[field]['coding'][0]['code']\n",
    "            display = None if not field == 'code' else condition[field]['coding'][0]['display']\n",
    "            condition_json_obj[field] = val\n",
    "            if not display == None:\n",
    "                condition_json_obj[\"condition\"] = display\n",
    "    conditions_obj[\"conditions\"].append(condition_json_obj)\n",
    "\n",
    "formatted_conditions_json = json.dumps(conditions_obj, indent=2) # indented for ease-of-reading for this demo\n",
    "\n",
    "print(formatted_conditions_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prompt Engineering\n",
    "\n",
    "### 3.1. Injecting context into the prompt\n",
    "Retrieval Augmented Generation (RAG) refers to retrieving relevant data to use in context of the prompt to provide the model with up-to-date or relevant information. Reading the code below, we see the prompt is asking the model to provide a list of medical conditions the patient has or previously had that may be relevant to their current clinical encounter. The complain and today's date are added, but the RAG concept is achieved by providing the patient's condition history as context. We also clearly label the context and the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Patient Record:\n",
      "{\"clinicalStatus\":\"resolved\",\"verificationStatus\":\"confirmed\",\"code\":\"302932006\",\"condition\":\"Tear of medial meniscus of knee\",\"onsetDateTime\":\"2022-02-01\",\"abatementDateTime\":\"2022-03-15\",\"recordedDate\":\"2022-03-15\"}\n",
      "\n",
      "Task:\n",
      "The current date is 2023-12-01. Use exact values from the above patient record to answer the question below. \n",
      "If the record does not contain relevant conditions, respond with the single word NO.\n",
      "A patient is currently being examined by a doctor with a chief complaint of: lump behind knee.\n",
      "Respond in JSON format with this template: \n",
      "{\n",
      "    \"FoundRelevantConditions\":BOOLEAN,\n",
      "    \"RelevantConditionsWithDates\":ARRAY,\n",
      "    \"ShortExplanation\":STRING\n",
      "}\n",
      "Using the patient's record, create a bulleted list of conditions with a high probability of helping diagnose or treat the chief complaint.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "\n",
    "chief_complaint = \"lump behind knee\"\n",
    "prompt = \"\"\"\n",
    "PATIENT RECORD:\n",
    "{context}\n",
    "\n",
    "TASK:\n",
    "The current date is {date}. Use exact values from the above patient record to answer the question below. \n",
    "If the record does not contain relevant conditions, respond with the single word NO.\n",
    "A patient is currently being examined by a doctor with a chief complaint of: {complaint}.\n",
    "Respond in JSON format with this template: \n",
    "{{\n",
    "    \"FoundRelevantConditions\":BOOLEAN,\n",
    "    \"RelevantConditionsWithDates\":ARRAY,\n",
    "    \"ShortExplanation\":STRING\n",
    "}}\n",
    "Using the patient's record, create a list of conditions with a high probability of helping diagnose or treat the chief complaint.\n",
    "\"\"\".format(context = '{\"clinicalStatus\":\"resolved\",\"verificationStatus\":\"confirmed\",\"code\":\"302932006\",\"condition\":\"Tear of medial meniscus of knee\",\"onsetDateTime\":\"2022-02-01\",\"abatementDateTime\":\"2022-03-15\",\"recordedDate\":\"2022-03-15\"}', date = date.today(), complaint = chief_complaint)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Structured responses lead to more consistent results\n",
    "Two parts of this prompt are important for achieving useful results. First is to clearly state what to do if the request cannot be completed. Without this, the model will imagine it's own response which leads to inconsistent output. Second, we are requesting that the output be structured in JSON. The property names themselves imply tasks for the LLM to complete, creating a double-check of its work. Removing the `FoundRelevantConditions` BOOLEAN property can lead to interesting results for various chief complaints.\n",
    "\n",
    "Experiment with the chief complaint. Try \"lower back pain\", \"migraine\", or \"difficulty breathing\". Also experiment with the prompt, change the wording, add/remove JSON properties from the response template, and change the `temperature` variable (0.0-1.0) in the `body` object. Higher temperature leads to higher \"creativity\" of the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {\n",
      "  \"FoundRelevantConditions\": true, \n",
      "  \"RelevantConditionsWithDates\": [\n",
      "    {\n",
      "      \"condition\": \"Tear of medial meniscus of knee\",\n",
      "      \"onsetDateTime\": \"2022-02-01\",\n",
      "      \"abatementDateTime\": \"2022-03-15\"\n",
      "    },\n",
      "    {\n",
      "      \"condition\": \"Acute meniscal tear, medial\",\n",
      "      \"onsetDateTime\": \"2022-08-01\",\n",
      "      \"abatementDateTime\": \"2022-09-15\"\n",
      "    }\n",
      "  ],\n",
      "  \"ShortExplanation\": \"The patient has a history of medial meniscus tears which can cause lower back pain.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "\n",
    "chief_complaint = \"lower back pain\"\n",
    "prompt = \"\"\"\n",
    "PATIENT RECORD:\n",
    "{context}\n",
    "\n",
    "TASK:\n",
    "The current date is {date}. Use exact values from the above patient record to answer the question below. \n",
    "If the record does not contain relevant conditions, respond with the single word NO.\n",
    "A patient is currently being examined by a doctor with a chief complaint of: {complaint}.\n",
    "Respond in JSON format with this template: \n",
    "{{\n",
    "    \"FoundRelevantConditions\":BOOLEAN,\n",
    "    \"RelevantConditionsWithDates\":ARRAY,\n",
    "    \"ShortExplanation\":STRING\n",
    "}}\n",
    "Using the patient's record, create a list of conditions with a high probability of helping diagnose or treat the chief complaint.\n",
    "\"\"\".format(context = formatted_conditions_json, date = date.today(), complaint = chief_complaint)\n",
    "\n",
    "body = json.dumps({\n",
    "    \"prompt\": \"\\n\\nHuman: {prompt}\\n\\nAssistant:\".format(prompt = prompt),\n",
    "    \"max_tokens_to_sample\": 1000,\n",
    "    \"temperature\": 0.1,\n",
    "    \"top_p\": 0.9,\n",
    "})\n",
    "\n",
    "response = bedrock_runtime.invoke_model(body=body, modelId=model_id, accept=accept, contentType=content_type)\n",
    "response_body = json.loads(response.get('body').read())\n",
    "print(response_body.get('completion'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
